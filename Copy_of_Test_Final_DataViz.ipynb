{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNuA8RGRMEYckEAxZ9Bqcz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/znumunz/dataviz2025/blob/main/Copy_of_Test_Final_DataViz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
      ],
      "metadata": {
        "id": "VqIlkb-pIhiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# base_path = '/content/drive/MyDrive/Data_Final_DataViz'"
      ],
      "metadata": {
        "id": "4hXPQFUnIlB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1k3PNaLUJnXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_film = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Netflix Films')\n",
        "df_nf_scores = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Rotten Tomatoes Score')\n",
        "df_im = pd.read_csv(\"/content/drive/MyDrive/Final DataViz2025/imdb_top_1000.csv\")"
      ],
      "metadata": {
        "id": "5Dp-11fQJIHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
      ],
      "metadata": {
        "id": "nK6zv_XNAXTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_film.head(3)"
      ],
      "metadata": {
        "id": "ZC2fyVeqOiMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_film.isnull().sum()"
      ],
      "metadata": {
        "id": "_Ai_QNN0CF3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rji8QUnLC5Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30bf8500"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_nf_film['Release Year'].plot(kind='hist', bins=30)\n",
        "plt.title('Distribution of Movie Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_scores.head(3)"
      ],
      "metadata": {
        "id": "a2u-N_jiQggA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff4df332"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_nf_scores['TOMATOMETER'].plot(kind='hist', bins=30)\n",
        "plt.title('Distribution of TOMATOMETER Scores')\n",
        "plt.xlabel('TOMATOMETER Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_scores.isnull().sum()"
      ],
      "metadata": {
        "id": "plw8OqeUCKtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_im.head(3)"
      ],
      "metadata": {
        "id": "GYogM3SRyY7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_im.isnull().sum()"
      ],
      "metadata": {
        "id": "0yRdSz4eCSmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏û‡∏°‡πå‡πÄ‡∏•‡πá‡∏Å‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏¥‡πÄ‡∏®‡∏©"
      ],
      "metadata": {
        "id": "uqm-_cUYAfeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean movie titles\n",
        "def clean_title(title):\n",
        "    if isinstance(title, str):\n",
        "        title = title.lower().strip()\n",
        "        # Remove special characters (keeping letters, numbers, and spaces)\n",
        "        title = ''.join(e for e in title if e.isalnum() or e.isspace())\n",
        "    return title\n",
        "\n",
        "# Apply cleaning to df_nf_film before merging\n",
        "df_nf_film['Movie Title'] = df_nf_film['Movie Title'].apply(clean_title)\n",
        "df_nf_scores['Movie Title'] = df_nf_scores['Movie Title'].apply(clean_title)\n",
        "df_im['Series_Title'] = df_im['Series_Title'].apply(clean_title)"
      ],
      "metadata": {
        "id": "NMXetemcUN4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge netflix_film and tomato_scores"
      ],
      "metadata": {
        "id": "aZHoGwjZAtKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.merge(df_nf_film, df_nf_scores, on='Movie Title', how='inner')\n",
        "df"
      ],
      "metadata": {
        "id": "RBUWC2DdTagN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "3EaWTQxlWI17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "609252f5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the number of null values per column\n",
        "null_counts = df.isnull().sum()\n",
        "\n",
        "# Filter out columns with no null values for better visualization\n",
        "null_counts = null_counts[null_counts > 0]\n",
        "\n",
        "if not null_counts.empty:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    null_counts.plot(kind='bar')\n",
        "    plt.title('Number of Null Values per Column in df')\n",
        "    plt.xlabel('Column')\n",
        "    plt.ylabel('Number of Null Values')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No null values found in the DataFrame df.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge (netflix_film and tomato_scores) and IMDB\n",
        "\n"
      ],
      "metadata": {
        "id": "NqTMbWffA7xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df1 = pd.merge(df, df_im, left_on='Movie Title',right_on ='Series_Title', how='left')\n",
        "# df1['Series_Title'].isnull().sum()\n",
        "df1"
      ],
      "metadata": {
        "id": "jLjegHayZ27f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î tpye"
      ],
      "metadata": {
        "id": "VZEBeMoFBGWW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9bf7116"
      },
      "source": [
        "df1['Type'] = df1['IMDB_Rating'].apply(lambda x: 'Movie' if pd.isnull(x) else 'Original Netflix Films')\n",
        "display(df1.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏£‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£"
      ],
      "metadata": {
        "id": "SOXvxYG3BOHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1=df1[['Movie Title','Director_x','Genre_x','Country','Rating','TOMATOMETER','AUDIENCE SCORE','IMDB_Rating','Type','Release Year']]\n",
        "df_1"
      ],
      "metadata": {
        "id": "pzCp_vuA0ebM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "664faefb"
      },
      "source": [
        "df1 = df1.rename(columns=lambda x: x.replace('_x', '') if '_x' in x else x)\n",
        "display(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fillna \"IMDB_Rating\":0"
      ],
      "metadata": {
        "id": "DUfjTqQvBTBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = df_1.fillna({\"IMDB_Rating\":0})\n",
        "df_1"
      ],
      "metadata": {
        "id": "1jJJaIAl4Ve4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1=df_1.dropna()"
      ],
      "metadata": {
        "id": "2ZqWUFHbE519"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.isnull().sum()"
      ],
      "metadata": {
        "id": "Y1hZQFWIaLq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1"
      ],
      "metadata": {
        "id": "_B_uTo6AFKV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81e972b7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the occurrences of each rating\n",
        "rating_counts = df_1['Type'].value_counts()\n",
        "\n",
        "# Create a pie chart\n",
        "plt.figure(figsize=(4, 4)) # Increase figure size further\n",
        "plt.pie(rating_counts, labels=rating_counts.index, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 10})\n",
        "plt.title('Distribution of Movie Ratings')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd1eb59e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_1['AUDIENCE SCORE'].plot(kind='hist', bins=20)\n",
        "plt.title('Distribution of Audience Scores')\n",
        "plt.xlabel('Audience Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "345e5053"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "average_scores_by_year.plot(kind='bar', figsize=(12, 7))\n",
        "plt.title('Average TOMATOMETER and Audience Score by Release Year (Last 10 Years)')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(['TOMATOMETER', 'AUDIENCE SCORE'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#normalize data ‡πÅ‡∏¢‡∏Å director ‡πÅ‡∏•‡∏∞ genre ‡∏≠‡∏≠‡∏Å ‡πÑ‡∏°‡πÉ‡∏´‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏≠‡∏¢‡πà‡∏π‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô"
      ],
      "metadata": {
        "id": "1DQW37npBbHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1:  ---\n",
        "\n",
        "def clean_title(title):\n",
        "    \"\"\"\n",
        "    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡∏±‡∏á\n",
        "    - ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å ‡∏•‡∏ö‡∏Ç‡∏≠‡∏ö\n",
        "    - ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "    - * ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ñ‡πâ‡∏≤ input ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà string (‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç) ‡∏à‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ NaN *\n",
        "    \"\"\"\n",
        "    if isinstance(title, str):\n",
        "        title = title.lower()\n",
        "        title = title.strip()\n",
        "        # Remove special characters (keeping letters, numbers, and spaces)\n",
        "        title = ''.join(e for e in title if e.isalnum() or e.isspace())\n",
        "\n",
        "        # ‡∏ñ‡πâ‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡∏Å‡πá‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô NaN\n",
        "        if not title:\n",
        "            return np.nan\n",
        "        return title\n",
        "\n",
        "    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà string (‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel) ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ NaN\n",
        "    return np.nan\n",
        "\n",
        "def normalize_column(df, id_col, value_col):\n",
        "    \"\"\"\n",
        "    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô \"Action, Drama\") ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ñ‡∏ß\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    - id_col (str): ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô ID ‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏ä‡πà‡∏ô 'Movie Title Cleaned')\n",
        "    - value_col (str): ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏ï‡∏Å (‡πÄ‡∏ä‡πà‡∏ô 'Genre' ‡∏´‡∏£‡∏∑‡∏≠ 'Director')\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (NaN) ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏ô‡∏∂‡πà‡∏á\n",
        "    df_normalized = df[[id_col, value_col]].dropna(subset=[id_col, value_col])\n",
        "\n",
        "    # 2. ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ñ‡πà‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô Genre, Director) ‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ .str.split ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ\n",
        "    df_normalized = df_normalized.astype({value_col: str})\n",
        "\n",
        "    # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á List ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£ split ‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏ß‡∏¢ ',' (‡πÄ‡∏ä‡πà‡∏ô \"A, B\" -> [\"A\", \"B\"])\n",
        "    # .assign ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡∏°‡πà‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏ä‡∏∑‡πà‡∏≠ 'SplitVal'\n",
        "    df_normalized = df_normalized.assign(SplitVal=df_normalized[value_col].str.split(','))\n",
        "\n",
        "    # 4. \"‡∏£‡∏∞‡πÄ‡∏ö‡∏¥‡∏î\" (explode) list ‡πÉ‡∏ô 'SplitVal' ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ñ‡∏ß‡πÉ‡∏´‡∏°‡πà\n",
        "    # (‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å: ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ [\"A\", \"B\"] ‡∏à‡∏∞‡∏Å‡∏•‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≠‡∏á‡πÅ‡∏ñ‡∏ß: ‡πÅ‡∏ñ‡∏ß A ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏ñ‡∏ß B)\n",
        "    df_normalized = df_normalized.explode('SplitVal')\n",
        "\n",
        "    # 5. ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á (whitespace) ‡∏ó‡∏µ‡πà‡∏´‡∏±‡∏ß‡πÅ‡∏•‡∏∞‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å split (‡πÄ‡∏ä‡πà‡∏ô \" Action\" -> \"Action\")\n",
        "    df_normalized['SplitVal'] = df_normalized['SplitVal'].str.strip()\n",
        "\n",
        "    # 6. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå id ‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà split ‡πÅ‡∏•‡πâ‡∏ß\n",
        "    df_normalized = df_normalized[[id_col, 'SplitVal']]\n",
        "\n",
        "    # 7. ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏ô‡∏±‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô, ‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)\n",
        "    df_normalized = df_normalized.drop_duplicates()\n",
        "\n",
        "    # 8. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡∏™‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢\n",
        "    final_col_name = value_col.lower().replace(\" \", \"_\") # ‡πÄ‡∏ä‡πà‡∏ô 'Director' -> 'director'\n",
        "    df_normalized = df_normalized.rename(columns={\n",
        "        id_col: 'title_cleaned',\n",
        "        'SplitVal': final_col_name\n",
        "    })\n",
        "\n",
        "    return df_normalized\n",
        "\n",
        "# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2:  (Main Execution) ---\n",
        "\n",
        "try:\n",
        "    # --- 2.1 ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (‡∏ï‡∏≤‡∏° Path ‡πÉ‡∏ô Google Drive ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì) ---\n",
        "    # imdb_file_path = '/content/drive/MyDrive/Python&DataViz2025/final_exam/imdb_top_1000.csv'\n",
        "    # netflix_file_path = '/content/drive/MyDrive/Python&DataViz2025/final_exam/Netflix-movies.xlsx'\n",
        "\n",
        "    df_nf_film = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Netflix Films')\n",
        "    # df_nf_scores = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Rotten Tomatoes Score')\n",
        "    df_im = pd.read_csv(\"/content/drive/MyDrive/Final DataViz2025/imdb_top_1000.csv\")\n",
        "\n",
        "    # --- 2.2 ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---\n",
        "    # print(f\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î {imdb_file_path}...\")\n",
        "    imdb_data = df_im\n",
        "\n",
        "    # === [‡∏à‡∏∏‡∏î‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç] ===\n",
        "    # ‡πÉ‡∏ä‡πâ pd.read_excel ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏ sheet_name ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
        "    # print(f\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î {netflix_file_path} (‡∏ä‡∏µ‡∏ï 'Netflix Films')...\")\n",
        "    netflix_films_data = df_nf_film\n",
        "    # ==================\n",
        "\n",
        "    # --- 2.3 ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡∏±‡∏á (‡∏™‡∏£‡πâ‡∏≤‡∏á 'Movie Title Cleaned') ---\n",
        "    print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏ô‡∏±‡∏á...\")\n",
        "    imdb_data['Movie Title Cleaned'] = imdb_data['Series_Title'].apply(clean_title)\n",
        "    netflix_films_data['Movie Title Cleaned'] = netflix_films_data['Movie Title'].apply(clean_title)\n",
        "\n",
        "    # --- 2.4 Normalize ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Director ---\n",
        "    print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Directors...\")\n",
        "    imdb_directors = normalize_column(imdb_data, 'Movie Title Cleaned', 'Director')\n",
        "    netflix_directors = normalize_column(netflix_films_data, 'Movie Title Cleaned', 'Director')\n",
        "\n",
        "    # ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á Director ‡∏à‡∏≤‡∏Å 2 ‡πÅ‡∏´‡∏•‡πà‡∏á ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ã‡πâ‡∏≥\n",
        "    all_directors = pd.concat([imdb_directors, netflix_directors]).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # --- 2.5 Normalize ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Genre ---\n",
        "    print(\"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Genres...\")\n",
        "    imdb_genres = normalize_column(imdb_data, 'Movie Title Cleaned', 'Genre')\n",
        "    netflix_genres = normalize_column(netflix_films_data, 'Movie Title Cleaned', 'Genre')\n",
        "\n",
        "    # ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á Genre ‡∏à‡∏≤‡∏Å 2 ‡πÅ‡∏´‡∏•‡πà‡∏á ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ã‡πâ‡∏≥\n",
        "    all_genres = pd.concat([imdb_genres, netflix_genres]).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # --- 2.6 ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---\n",
        "\n",
        "    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô CSV (‡πÉ‡∏ô /content/ ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á Colab)\n",
        "    output_director_path = \"/content/normalized_directors.csv\"\n",
        "    output_genre_path = \"/content/normalized_genres.csv\"\n",
        "\n",
        "    all_directors.to_csv(output_director_path, index=False)\n",
        "    all_genres.to_csv(output_genre_path, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"--- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Normalized Directors (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 50 ‡πÅ‡∏ñ‡∏ß) ---\")\n",
        "    print(all_directors.head(50))\n",
        "\n",
        "    print(\"\\n--- ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Normalized Genres (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 50 ‡πÅ‡∏ñ‡∏ß) ---\")\n",
        "    print(all_genres.head(50))\n",
        "\n",
        "    print(f\"\\n[‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!] ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå '{output_director_path}' ({len(all_directors)} ‡πÅ‡∏ñ‡∏ß) ‡πÅ‡∏•‡∏∞ '{output_genre_path}' ({len(all_genres)} ‡πÅ‡∏ñ‡∏ß) ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß\")\n",
        "\n",
        "except KeyError as e:\n",
        "    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏ä‡πà‡∏ô 'Director' ‡∏´‡∏£‡∏∑‡∏≠ 'Genre') ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
        "    print(f\"\\n[‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: KeyError]\")\n",
        "    print(f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏: {e}\")\n",
        "    print(\"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠\n",
        "    print(f\"\\n[‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: FileNotFoundError]\")\n",
        "    print(f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {e.filename}\")\n",
        "    print(\"‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô Google Drive ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\")\n",
        "\n",
        "except Exception as e:\n",
        "    # ‡∏î‡∏±‡∏Å‡∏à‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î\n",
        "    print(f\"\\n[‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î]: {e}\")\n",
        "    import traceback\n",
        "    print(traceback.format_exc())"
      ],
      "metadata": {
        "id": "aP1BI_6i6V5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_genres"
      ],
      "metadata": {
        "id": "nhBFAt9_97Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_directors"
      ],
      "metadata": {
        "id": "SgmKhf1n9_oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1"
      ],
      "metadata": {
        "id": "cnpg_BNy-FeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgqW52t59ZWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å google sheets"
      ],
      "metadata": {
        "id": "ldeLtiGjILLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fek7UJhuDo8o"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# üöÄ Upload large DataFrames to separate Google Sheets (downsize + batch)\n",
        "# ============================================================\n",
        "\n",
        "!pip install gspread gspread_dataframe --quiet\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "import math\n",
        "\n",
        "# ============================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "2a03VEqS-ayj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ‚úÖ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞ DataFrame ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î\n",
        "sheets_info = {\n",
        "    \"df_1\": df_1,\n",
        "    \"all_directors\": all_directors,\n",
        "    \"all_genres\": all_genres\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# ‚úÖ ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ batch size (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á)\n",
        "BATCH_SIZE = 50000\n",
        "\n",
        "# ============================================================\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î DataFrame\n",
        "def downsize_df(df):\n",
        "    # ‡∏•‡∏î int64 ‚Üí int32\n",
        "    for col in df.select_dtypes(include=['int64']).columns:\n",
        "        df[col] = df[col].astype('int32')\n",
        "    # ‡∏•‡∏î float64 ‚Üí float32\n",
        "    for col in df.select_dtypes(include=['float64']).columns:\n",
        "        df[col] = df[col].astype('float32')\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á datetime ‚Üí string\n",
        "    for col in df.select_dtypes(include=['datetime', 'datetimetz']).columns:\n",
        "        df[col] = df[col].astype(str)\n",
        "    return df\n",
        "\n",
        "# ============================================================\n",
        "# ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏µ‡∏•‡∏∞ DataFrame\n",
        "for sheet_title, df in sheets_info.items():\n",
        "    print(f\"\\nüì§ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î '{sheet_title}'...\")\n",
        "\n",
        "    df = downsize_df(df)  # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "    total_rows = df.shape[0]\n",
        "    num_batches = math.ceil(total_rows / BATCH_SIZE)\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Google Sheet ‡πÉ‡∏´‡∏°‡πà\n",
        "    sh = gc.create(sheet_title)\n",
        "    sh.share(None, perm_type='anyone', role='writer')  # ‡πÉ‡∏Ñ‡∏£‡∏Å‡πá‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡∏π‡πÑ‡∏î‡πâ\n",
        "    ws = sh.sheet1\n",
        "\n",
        "    print(f\"‚ÑπÔ∏è Total rows: {total_rows}, will upload in {num_batches} batches of {BATCH_SIZE}\")\n",
        "\n",
        "    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î batch ‡πÅ‡∏£‡∏Å ‡∏û‡∏£‡πâ‡∏≠‡∏° header\n",
        "    batch = df.iloc[0:min(BATCH_SIZE, total_rows)]\n",
        "    set_with_dataframe(ws, batch, include_index=False, include_column_header=True)\n",
        "\n",
        "    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î batch ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
        "    for i in range(1, num_batches):\n",
        "        start_row = i * BATCH_SIZE\n",
        "        end_row = min((i+1)*BATCH_SIZE, total_rows)\n",
        "        batch = df.iloc[start_row:end_row]\n",
        "        set_with_dataframe(ws, batch, include_index=False, include_column_header=False, row=start_row+1)\n",
        "        print(f\"‚è≥ Uploaded rows {start_row} to {end_row}\")\n",
        "\n",
        "    print(f\"‚úÖ Upload finished: '{sheet_title}' ({df.shape[0]} rows, {df.shape[1]} cols)\")\n",
        "    print(f\"üîó Google Sheets URL: https://docs.google.com/spreadsheets/d/{sh.id}\")\n",
        "\n",
        "print(\"\\nüéâ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!\")\n"
      ],
      "metadata": {
        "id": "1L4PFH-zIOWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Looker studio\n",
        "https://lookerstudio.google.com/reporting/480afa64-d1d1-45d2-963b-cf583065f708"
      ],
      "metadata": {
        "id": "SQHTR9A9GRgA"
      }
    }
  ]
}