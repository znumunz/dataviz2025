{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNuA8RGRMEYckEAxZ9Bqcz6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/znumunz/dataviz2025/blob/main/Copy_of_Test_Final_DataViz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# นำเข้าข้อมูล"
      ],
      "metadata": {
        "id": "VqIlkb-pIhiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# base_path = '/content/drive/MyDrive/Data_Final_DataViz'"
      ],
      "metadata": {
        "id": "4hXPQFUnIlB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1k3PNaLUJnXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_film = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Netflix Films')\n",
        "df_nf_scores = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Rotten Tomatoes Score')\n",
        "df_im = pd.read_csv(\"/content/drive/MyDrive/Final DataViz2025/imdb_top_1000.csv\")"
      ],
      "metadata": {
        "id": "5Dp-11fQJIHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# เช็คข้อมูล"
      ],
      "metadata": {
        "id": "nK6zv_XNAXTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_film.head(3)"
      ],
      "metadata": {
        "id": "ZC2fyVeqOiMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_film.isnull().sum()"
      ],
      "metadata": {
        "id": "_Ai_QNN0CF3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rji8QUnLC5Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30bf8500"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_nf_film['Release Year'].plot(kind='hist', bins=30)\n",
        "plt.title('Distribution of Movie Release Years')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_scores.head(3)"
      ],
      "metadata": {
        "id": "a2u-N_jiQggA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff4df332"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_nf_scores['TOMATOMETER'].plot(kind='hist', bins=30)\n",
        "plt.title('Distribution of TOMATOMETER Scores')\n",
        "plt.xlabel('TOMATOMETER Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nf_scores.isnull().sum()"
      ],
      "metadata": {
        "id": "plw8OqeUCKtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_im.head(3)"
      ],
      "metadata": {
        "id": "GYogM3SRyY7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_im.isnull().sum()"
      ],
      "metadata": {
        "id": "0yRdSz4eCSmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ปรับค่าคอลัมน์เป็นตัวพิพม์เล็กและลบค่าว่างกับตัวอักษรพิเศษ"
      ],
      "metadata": {
        "id": "uqm-_cUYAfeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean movie titles\n",
        "def clean_title(title):\n",
        "    if isinstance(title, str):\n",
        "        title = title.lower().strip()\n",
        "        # Remove special characters (keeping letters, numbers, and spaces)\n",
        "        title = ''.join(e for e in title if e.isalnum() or e.isspace())\n",
        "    return title\n",
        "\n",
        "# Apply cleaning to df_nf_film before merging\n",
        "df_nf_film['Movie Title'] = df_nf_film['Movie Title'].apply(clean_title)\n",
        "df_nf_scores['Movie Title'] = df_nf_scores['Movie Title'].apply(clean_title)\n",
        "df_im['Series_Title'] = df_im['Series_Title'].apply(clean_title)"
      ],
      "metadata": {
        "id": "NMXetemcUN4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge netflix_film and tomato_scores"
      ],
      "metadata": {
        "id": "aZHoGwjZAtKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.merge(df_nf_film, df_nf_scores, on='Movie Title', how='inner')\n",
        "df"
      ],
      "metadata": {
        "id": "RBUWC2DdTagN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "3EaWTQxlWI17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "609252f5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the number of null values per column\n",
        "null_counts = df.isnull().sum()\n",
        "\n",
        "# Filter out columns with no null values for better visualization\n",
        "null_counts = null_counts[null_counts > 0]\n",
        "\n",
        "if not null_counts.empty:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    null_counts.plot(kind='bar')\n",
        "    plt.title('Number of Null Values per Column in df')\n",
        "    plt.xlabel('Column')\n",
        "    plt.ylabel('Number of Null Values')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No null values found in the DataFrame df.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge (netflix_film and tomato_scores) and IMDB\n",
        "\n"
      ],
      "metadata": {
        "id": "NqTMbWffA7xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df1 = pd.merge(df, df_im, left_on='Movie Title',right_on ='Series_Title', how='left')\n",
        "# df1['Series_Title'].isnull().sum()\n",
        "df1"
      ],
      "metadata": {
        "id": "jLjegHayZ27f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# กำหนด tpye"
      ],
      "metadata": {
        "id": "VZEBeMoFBGWW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9bf7116"
      },
      "source": [
        "df1['Type'] = df1['IMDB_Rating'].apply(lambda x: 'Movie' if pd.isnull(x) else 'Original Netflix Films')\n",
        "display(df1.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#เลือกเฉพราะคอลัมน์ที่ต้องการ"
      ],
      "metadata": {
        "id": "SOXvxYG3BOHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1=df1[['Movie Title','Director_x','Genre_x','Country','Rating','TOMATOMETER','AUDIENCE SCORE','IMDB_Rating','Type','Release Year']]\n",
        "df_1"
      ],
      "metadata": {
        "id": "pzCp_vuA0ebM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "664faefb"
      },
      "source": [
        "df1 = df1.rename(columns=lambda x: x.replace('_x', '') if '_x' in x else x)\n",
        "display(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#fillna \"IMDB_Rating\":0"
      ],
      "metadata": {
        "id": "DUfjTqQvBTBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_1 = df_1.fillna({\"IMDB_Rating\":0})\n",
        "df_1"
      ],
      "metadata": {
        "id": "1jJJaIAl4Ve4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1=df_1.dropna()"
      ],
      "metadata": {
        "id": "2ZqWUFHbE519"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1.isnull().sum()"
      ],
      "metadata": {
        "id": "Y1hZQFWIaLq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1"
      ],
      "metadata": {
        "id": "_B_uTo6AFKV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81e972b7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the occurrences of each rating\n",
        "rating_counts = df_1['Type'].value_counts()\n",
        "\n",
        "# Create a pie chart\n",
        "plt.figure(figsize=(4, 4)) # Increase figure size further\n",
        "plt.pie(rating_counts, labels=rating_counts.index, autopct='%1.1f%%', startangle=140, textprops={'fontsize': 10})\n",
        "plt.title('Distribution of Movie Ratings')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd1eb59e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_1['AUDIENCE SCORE'].plot(kind='hist', bins=20)\n",
        "plt.title('Distribution of Audience Scores')\n",
        "plt.xlabel('Audience Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "345e5053"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "average_scores_by_year.plot(kind='bar', figsize=(12, 7))\n",
        "plt.title('Average TOMATOMETER and Audience Score by Release Year (Last 10 Years)')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(['TOMATOMETER', 'AUDIENCE SCORE'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#normalize data แยก director และ genre ออก ไมให้หลายค่าอยู่ในคอลัมน์เดียวกัน"
      ],
      "metadata": {
        "id": "1DQW37npBbHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# --- ส่วนที่ 1:  ---\n",
        "\n",
        "def clean_title(title):\n",
        "    \"\"\"\n",
        "    ฟังก์ชันทำความสะอาดชื่อหนัง\n",
        "    - แปลงเป็นตัวพิมพ์เล็ก ลบขอบ\n",
        "    - ลบอักขระพิเศษ\n",
        "    - * สำคัญ: ถ้า input ไม่ใช่ string (เช่น ตัวเลข) จะคืนค่า NaN *\n",
        "    \"\"\"\n",
        "    if isinstance(title, str):\n",
        "        title = title.lower()\n",
        "        title = title.strip()\n",
        "        # Remove special characters (keeping letters, numbers, and spaces)\n",
        "        title = ''.join(e for e in title if e.isalnum() or e.isspace())\n",
        "\n",
        "        # ถ้าผลลัพธ์เป็นสตริงว่างเปล่า ก็ให้เป็น NaN\n",
        "        if not title:\n",
        "            return np.nan\n",
        "        return title\n",
        "\n",
        "    # ถ้าไม่ใช่ string (เช่น ตัวเลขจากไฟล์ Excel) ให้คืนค่า NaN\n",
        "    return np.nan\n",
        "\n",
        "def normalize_column(df, id_col, value_col):\n",
        "    \"\"\"\n",
        "    ฟังก์ชันสำหรับแตกคอลัมน์ที่มีหลายค่า (เช่น \"Action, Drama\") ออกเป็นหลายแถว\n",
        "\n",
        "    Parameters:\n",
        "    - df (DataFrame): ตารางข้อมูล\n",
        "    - id_col (str): ชื่อคอลัมน์ที่เป็น ID หลัก (เช่น 'Movie Title Cleaned')\n",
        "    - value_col (str): ชื่อคอลัมน์ที่ต้องการแตก (เช่น 'Genre' หรือ 'Director')\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. เลือกเฉพาะคอลัมน์ที่ต้องการ และลบแถวที่มีค่าว่าง (NaN) ในคอลัมน์ใดคอลัมน์หนึ่ง\n",
        "    df_normalized = df[[id_col, value_col]].dropna(subset=[id_col, value_col])\n",
        "\n",
        "    # 2. แปลงคอลัมน์ค่า (เช่น Genre, Director) เป็น string เพื่อให้ .str.split ทำงานได้\n",
        "    df_normalized = df_normalized.astype({value_col: str})\n",
        "\n",
        "    # 3. สร้าง List โดยการ split ค่าด้วย ',' (เช่น \"A, B\" -> [\"A\", \"B\"])\n",
        "    # .assign จะสร้างคอลัมน์ใหม่ชั่วคราวชื่อ 'SplitVal'\n",
        "    df_normalized = df_normalized.assign(SplitVal=df_normalized[value_col].str.split(','))\n",
        "\n",
        "    # 4. \"ระเบิด\" (explode) list ใน 'SplitVal' ออกเป็นแถวใหม่\n",
        "    # (นี่คือหัวใจหลัก: แถวที่มี [\"A\", \"B\"] จะกลายเป็นสองแถว: แถว A และ แถว B)\n",
        "    df_normalized = df_normalized.explode('SplitVal')\n",
        "\n",
        "    # 5. ลบช่องว่าง (whitespace) ที่หัวและท้ายของค่าที่ถูก split (เช่น \" Action\" -> \"Action\")\n",
        "    df_normalized['SplitVal'] = df_normalized['SplitVal'].str.strip()\n",
        "\n",
        "    # 6. เลือกเฉพาะคอลัมน์ id และค่าที่ split แล้ว\n",
        "    df_normalized = df_normalized[[id_col, 'SplitVal']]\n",
        "\n",
        "    # 7. ลบแถวที่ซ้ำกัน (เช่น หนังเรื่องเดียวกัน, ผู้กำกับคนเดียวกัน)\n",
        "    df_normalized = df_normalized.drop_duplicates()\n",
        "\n",
        "    # 8. เปลี่ยนชื่อคอลัมน์ให้สื่อความหมาย\n",
        "    final_col_name = value_col.lower().replace(\" \", \"_\") # เช่น 'Director' -> 'director'\n",
        "    df_normalized = df_normalized.rename(columns={\n",
        "        id_col: 'title_cleaned',\n",
        "        'SplitVal': final_col_name\n",
        "    })\n",
        "\n",
        "    return df_normalized\n",
        "\n",
        "# --- ส่วนที่ 2:  (Main Execution) ---\n",
        "\n",
        "try:\n",
        "    # --- 2.1 กำหนดชื่อไฟล์ (ตาม Path ใน Google Drive ของคุณ) ---\n",
        "    # imdb_file_path = '/content/drive/MyDrive/Python&DataViz2025/final_exam/imdb_top_1000.csv'\n",
        "    # netflix_file_path = '/content/drive/MyDrive/Python&DataViz2025/final_exam/Netflix-movies.xlsx'\n",
        "\n",
        "    df_nf_film = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Netflix Films')\n",
        "    # df_nf_scores = pd.read_excel(\"/content/drive/MyDrive/Final DataViz2025/Netflix-movies.xlsx\",sheet_name='Rotten Tomatoes Score')\n",
        "    df_im = pd.read_csv(\"/content/drive/MyDrive/Final DataViz2025/imdb_top_1000.csv\")\n",
        "\n",
        "    # --- 2.2 โหลดข้อมูล ---\n",
        "    # print(f\"กำลังโหลด {imdb_file_path}...\")\n",
        "    imdb_data = df_im\n",
        "\n",
        "    # === [จุดแก้ไข] ===\n",
        "    # ใช้ pd.read_excel และระบุ sheet_name ที่ถูกต้อง\n",
        "    # print(f\"กำลังโหลด {netflix_file_path} (ชีต 'Netflix Films')...\")\n",
        "    netflix_films_data = df_nf_film\n",
        "    # ==================\n",
        "\n",
        "    # --- 2.3 ทำความสะอาดชื่อหนัง (สร้าง 'Movie Title Cleaned') ---\n",
        "    print(\"กำลังทำความสะอาดชื่อหนัง...\")\n",
        "    imdb_data['Movie Title Cleaned'] = imdb_data['Series_Title'].apply(clean_title)\n",
        "    netflix_films_data['Movie Title Cleaned'] = netflix_films_data['Movie Title'].apply(clean_title)\n",
        "\n",
        "    # --- 2.4 Normalize ตาราง Director ---\n",
        "    print(\"กำลังประมวลผล Directors...\")\n",
        "    imdb_directors = normalize_column(imdb_data, 'Movie Title Cleaned', 'Director')\n",
        "    netflix_directors = normalize_column(netflix_films_data, 'Movie Title Cleaned', 'Director')\n",
        "\n",
        "    # รวมตาราง Director จาก 2 แหล่ง และลบแถวซ้ำ\n",
        "    all_directors = pd.concat([imdb_directors, netflix_directors]).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # --- 2.5 Normalize ตาราง Genre ---\n",
        "    print(\"กำลังประมวลผล Genres...\")\n",
        "    imdb_genres = normalize_column(imdb_data, 'Movie Title Cleaned', 'Genre')\n",
        "    netflix_genres = normalize_column(netflix_films_data, 'Movie Title Cleaned', 'Genre')\n",
        "\n",
        "    # รวมตาราง Genre จาก 2 แหล่ง และลบแถวซ้ำ\n",
        "    all_genres = pd.concat([imdb_genres, netflix_genres]).drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "    # --- 2.6 บันทึกไฟล์และแสดงผลลัพธ์ ---\n",
        "\n",
        "    # บันทึกเป็น CSV (ใน /content/ ซึ่งเป็นพื้นที่ชั่วคราวของ Colab)\n",
        "    output_director_path = \"/content/normalized_directors.csv\"\n",
        "    output_genre_path = \"/content/normalized_genres.csv\"\n",
        "\n",
        "    all_directors.to_csv(output_director_path, index=False)\n",
        "    all_genres.to_csv(output_genre_path, index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"--- ตาราง Normalized Directors (ตัวอย่าง 50 แถว) ---\")\n",
        "    print(all_directors.head(50))\n",
        "\n",
        "    print(\"\\n--- ตาราง Normalized Genres (ตัวอย่าง 50 แถว) ---\")\n",
        "    print(all_genres.head(50))\n",
        "\n",
        "    print(f\"\\n[สำเร็จ!] สร้างไฟล์ '{output_director_path}' ({len(all_directors)} แถว) และ '{output_genre_path}' ({len(all_genres)} แถว) เรียบร้อยแล้ว\")\n",
        "\n",
        "except KeyError as e:\n",
        "    # กรณีที่ชื่อคอลัมน์ (เช่น 'Director' หรือ 'Genre') ไม่ถูกต้อง\n",
        "    print(f\"\\n[เกิดข้อผิดพลาด: KeyError]\")\n",
        "    print(f\"ไม่พบคอลัมน์ที่ระบุ: {e}\")\n",
        "    print(\"กรุณาตรวจสอบชื่อคอลัมน์ในไฟล์ของคุณ\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    # กรณีที่หาไฟล์ไม่เจอ\n",
        "    print(f\"\\n[เกิดข้อผิดพลาด: FileNotFoundError]\")\n",
        "    print(f\"ไม่พบไฟล์: {e.filename}\")\n",
        "    print(\"กรุณาตรวจสอบ Path ไปยังไฟล์ใน Google Drive ของคุณ\")\n",
        "\n",
        "except Exception as e:\n",
        "    # ดักจับข้อผิดพลาดอื่นๆ ที่ไม่คาดคิด\n",
        "    print(f\"\\n[เกิดข้อผิดพลาดที่ไม่คาดคิด]: {e}\")\n",
        "    import traceback\n",
        "    print(traceback.format_exc())"
      ],
      "metadata": {
        "id": "aP1BI_6i6V5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_genres"
      ],
      "metadata": {
        "id": "nhBFAt9_97Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_directors"
      ],
      "metadata": {
        "id": "SgmKhf1n9_oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_1"
      ],
      "metadata": {
        "id": "cnpg_BNy-FeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgqW52t59ZWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ส่งออก google sheets"
      ],
      "metadata": {
        "id": "ldeLtiGjILLj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fek7UJhuDo8o"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 🚀 Upload large DataFrames to separate Google Sheets (downsize + batch)\n",
        "# ============================================================\n",
        "\n",
        "!pip install gspread gspread_dataframe --quiet\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "import pandas as pd\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "import math\n",
        "\n",
        "# ============================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ เชื่อมต่อ Google Sheets\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "2a03VEqS-ayj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ✅ กำหนดชื่อไฟล์และ DataFrame ที่จะอัปโหลด\n",
        "sheets_info = {\n",
        "    \"df_1\": df_1,\n",
        "    \"all_directors\": all_directors,\n",
        "    \"all_genres\": all_genres\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# ✅ ตั้งค่า batch size (จำนวนแถวต่อครั้ง)\n",
        "BATCH_SIZE = 50000\n",
        "\n",
        "# ============================================================\n",
        "# ฟังก์ชันลดขนาด DataFrame\n",
        "def downsize_df(df):\n",
        "    # ลด int64 → int32\n",
        "    for col in df.select_dtypes(include=['int64']).columns:\n",
        "        df[col] = df[col].astype('int32')\n",
        "    # ลด float64 → float32\n",
        "    for col in df.select_dtypes(include=['float64']).columns:\n",
        "        df[col] = df[col].astype('float32')\n",
        "    # แปลง datetime → string\n",
        "    for col in df.select_dtypes(include=['datetime', 'datetimetz']).columns:\n",
        "        df[col] = df[col].astype(str)\n",
        "    return df\n",
        "\n",
        "# ============================================================\n",
        "# อัปโหลดทีละ DataFrame\n",
        "for sheet_title, df in sheets_info.items():\n",
        "    print(f\"\\n📤 กำลังอัปโหลด '{sheet_title}'...\")\n",
        "\n",
        "    df = downsize_df(df)  # ลดขนาดข้อมูล\n",
        "    total_rows = df.shape[0]\n",
        "    num_batches = math.ceil(total_rows / BATCH_SIZE)\n",
        "\n",
        "    # สร้าง Google Sheet ใหม่\n",
        "    sh = gc.create(sheet_title)\n",
        "    sh.share(None, perm_type='anyone', role='writer')  # ใครก็เข้าดูได้\n",
        "    ws = sh.sheet1\n",
        "\n",
        "    print(f\"ℹ️ Total rows: {total_rows}, will upload in {num_batches} batches of {BATCH_SIZE}\")\n",
        "\n",
        "    # อัปโหลด batch แรก พร้อม header\n",
        "    batch = df.iloc[0:min(BATCH_SIZE, total_rows)]\n",
        "    set_with_dataframe(ws, batch, include_index=False, include_column_header=True)\n",
        "\n",
        "    # อัปโหลด batch ถัดไป (ถ้ามี)\n",
        "    for i in range(1, num_batches):\n",
        "        start_row = i * BATCH_SIZE\n",
        "        end_row = min((i+1)*BATCH_SIZE, total_rows)\n",
        "        batch = df.iloc[start_row:end_row]\n",
        "        set_with_dataframe(ws, batch, include_index=False, include_column_header=False, row=start_row+1)\n",
        "        print(f\"⏳ Uploaded rows {start_row} to {end_row}\")\n",
        "\n",
        "    print(f\"✅ Upload finished: '{sheet_title}' ({df.shape[0]} rows, {df.shape[1]} cols)\")\n",
        "    print(f\"🔗 Google Sheets URL: https://docs.google.com/spreadsheets/d/{sh.id}\")\n",
        "\n",
        "print(\"\\n🎉 อัปโหลดครบทุกชุดข้อมูลเรียบร้อยแล้ว!\")\n"
      ],
      "metadata": {
        "id": "1L4PFH-zIOWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Looker studio\n",
        "https://lookerstudio.google.com/reporting/480afa64-d1d1-45d2-963b-cf583065f708"
      ],
      "metadata": {
        "id": "SQHTR9A9GRgA"
      }
    }
  ]
}